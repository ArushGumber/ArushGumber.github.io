<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications - Arush Gumber</title>
    <link rel="stylesheet" href="css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="index.html" class="nav-brand">Arush <span class="highlight">Gumber</span></a>
            <ul class="nav-menu">
                <li><a href="index.html">about</a></li>
                <li><a href="publications.html" class="active">publications</a></li>
                <li><a href="projects.html">projects</a></li>
                <li><a href="awards.html">awards</a></li>
                <li><a href="news.html">news</a></li>
            </ul>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="container">
        <section class="publications-section">
            <h1>publications</h1>
            <p class="subtitle">publications by categories in reversed chronological order.</p>

            <!-- Legend -->
            <div class="pub-legend">
                <span><strong>C</strong>=Conference,</span>
                <span><strong>W</strong>=Workshop,</span>
                <span><strong>S</strong>=Under Review</span>
            </div>

            <!-- 2026 Publications -->
            <div class="year-section">
                <h2 class="year">2026</h2>

                <!-- S.3 - FreqDINO -->
                <div class="publication">
                    <div class="pub-header">
                        <span class="pub-tag">S.3</span>
                        <div class="pub-content">
                            <h3>FreqDINO: Multi-Modal Deepfake Detection with Band-Conditioned Cross-Attention</h3>
                            <p class="authors"><strong>Arush Gumber</strong>, et al.</p>
                            <p class="venue"><strong>CVPR 2026</strong>: Manuscript under review (First Author)</p>
                            <p class="description">
                                Proposed FreqDINO, a multi-domain deepfake detector fusing semantic, frequency, and noise cues via a novel Band-Conditioned Phased Cross-Attention (BC-PCA). Achieved 98% F1 vs. 93.6% baseline with interpretable CLIP/DINO-based U-Net decoder.
                            </p>
                            <div class="pub-links">
                                <!-- <a href="#" class="pub-link">PDF</a> -->
                                <!-- <a href="#" class="pub-link">Code</a> -->
                                <span class="pub-status">Under Review</span>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- S.1 - TOAM-YOLO (PLACEHOLDER) -->
                <div class="publication">
                    <div class="pub-header">
                        <span class="pub-tag">S.1</span>
                        <div class="pub-content">
                            <h3>TOAM-YOLO: A Lightweight Tiny Object-Aware Multi-Expert Framework</h3>
                            <p class="authors"><strong>Arush Gumber</strong>, et al.</p>
                            <p class="venue"><strong>AAAI 2026</strong>: Manuscript under review (First Author)</p>
                            <p class="description">
                                Tiny object detection with 4M parameters achieving SOTA on 5 benchmarks. Novel TOA-MoE module with BiFPN fusion and CARAFE upsampling for efficient multi-scale feature processing.
                            </p>
                            <div class="pub-links">
                                <!-- <a href="#" class="pub-link">PDF</a> -->
                                <!-- TODO: Add arXiv link when available -->
                                <span class="pub-status">Under Review</span>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- W.1, S.2 - DentalNet -->
                <div class="publication">
                    <div class="pub-header">
                        <span class="pub-tag multi-tag">W.1<br>S.2</span>
                        <div class="pub-content">
                            <h3>DentalNet: Geometric Aware Multi-View Transformer for Dental 3D Scan Analysis</h3>
                            <p class="authors"><strong>Arush Gumber</strong>, et al.</p>
                            <p class="venue">
                                <strong>NeurIPS 2025 Imageomics Workshop</strong>: Accepted (First Author)<br>
                                <strong>AAAI 2026</strong>: Under review
                            </p>
                            <p class="description">
                                Multi-modal 2D/3D fusion achieving 67% F1-score. Cross-attention mechanism integrates 2D intraoral views with 3D point cloud representations for IOTN-DHC classification.
                            </p>
                            <div class="pub-links">
                                <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9qjHhXkAAAAJ&citation_for_view=9qjHhXkAAAAJ:9yKSN-GCB0IC" target="_blank" class="pub-link">Scholar</a>
                                <!-- <a href="#" class="pub-link">PDF</a> -->
                                <!-- <a href="#" class="pub-link">Code</a> -->
                            </div>
                        </div>
                    </div>
                </div>

                <!-- S.4 - Underwater Acoustic -->
                <div class="publication">
                    <div class="pub-header">
                        <span class="pub-tag">S.4</span>
                        <div class="pub-content">
                            <h3>Unified Framework for Underwater Acoustic Event Detection</h3>
                            <p class="authors"><strong>Arush Gumber</strong>, et al.</p>
                            <p class="venue"><strong>TMLR</strong>: In preparation</p>
                            <p class="description">
                                Harmonized datasets for marine soundscape monitoring. Standardized preprocessing pipeline with deep learning architecture for biodiversity assessment and vessel tracking.
                            </p>
                            <div class="pub-links">
                                <span class="pub-status">In Preparation</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- 2025 Publications -->
            <div class="year-section">
                <h2 class="year">2025</h2>

                <!-- C.1 - MSCAN -->
                <div class="publication">
                    <div class="pub-header">
                        <span class="pub-tag">C.1</span>
                        <div class="pub-content">
                            <h3>MSCAN: Multistage Spinal Canal Stenosis Grading Using Cross-Attention</h3>
                            <p class="authors"><strong>Arush Gumber</strong>, et al.</p>
                            <p class="venue"><strong>IEEE/CVF CVPR 2025 Demo Track</strong>: Accepted</p>
                            <p class="description">
                                Deep learning framework for automated MRI-based spinal stenosis grading achieving 0.971 AUROC with YOLO detection and multi-view cross-attention.
                            </p>
                            <div class="pub-links">
                                <a href="https://arxiv.org/abs/2503.01634" target="_blank" class="pub-link">arXiv</a>
                                <a href="https://github.com/Deep-learning-exp/M-SCAN" target="_blank" class="pub-link">Code</a>
                                <a href="https://www.youtube.com/watch?v=bVLlfGIOBiI" target="_blank" class="pub-link">Talk</a>
                            </div>
                            <!-- Embedded Video -->
                            <div class="video-embed">
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/bVLlfGIOBiI" 
                                    title="MSCAN Talk" frameborder="0" 
                                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                    allowfullscreen>
                                </iframe>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- C.2 - SocialDF -->
                <div class="publication">
                    <div class="pub-header">
                        <span class="pub-tag">C.2</span>
                        <div class="pub-content">
                            <h3>SocialDF: Benchmark Dataset and Detection Model for Deepfake Content</h3>
                            <p class="authors"><strong>Arush Gumber</strong>, et al.</p>
                            <p class="venue"><strong>ACM ICMR 2025: MAD Workshop</strong>: Accepted</p>
                            <p class="description">
                                Real-world benchmark with multi-agent LLM framework outperforming SOTA lip-sync methods through fact-checking integration.
                            </p>
                            <div class="pub-links">
                                <a href="https://dl.acm.org/doi/10.1145/3733567.3735573" target="_blank" class="pub-link">ACM DL</a>
                                <a href="https://www.youtube.com/watch?v=8i3ejDl3q_Q" target="_blank" class="pub-link">Talk</a>
                            </div>
                            <!-- Embedded Video -->
                            <div class="video-embed">
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/8i3ejDl3q_Q" 
                                    title="SocialDF Talk" frameborder="0" 
                                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                    allowfullscreen>
                                </iframe>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

        </section>
    </main>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 Arush Gumber. Built with HTML, CSS, and JavaScript.</p>
    </footer>

    <script src="js/main.js"></script>
</body>
</html>
