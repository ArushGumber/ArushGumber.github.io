<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Awards - Arush Gumber</title>
    <link rel="stylesheet" href="css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="index.html" class="nav-brand">Arush <span class="highlight">Gumber</span></a>
            <ul class="nav-menu">
                <li><a href="index.html">about</a></li>
                <li><a href="publications.html">publications</a></li>
                <li><a href="projects.html">projects</a></li>
                <li><a href="awards.html" class="active">awards</a></li>
                <li><a href="news.html">news</a></li>
            </ul>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="container">
        <section class="awards-section">
            <h1>awards</h1>
            <p class="subtitle">a list of my achievements throughout the years.</p>

            <div class="awards-list">
                
                <!-- Amazon ML Challenge 2025 -->
                <div class="award-item">
                    <div class="award-icon">üèÜ</div>
                    <div class="award-content">
                        <h3>Amazon ML Challenge 2025</h3>
                        <p class="award-rank">Rank 54 out of 20,000+ teams</p>
                        <p class="award-description">
                            Developed multimodal price prediction system fusing CLIP ViT-B/32 and DINOv2 visual embeddings with TF-IDF text features, achieving 42.386 SMAPE through cross-attention architecture with global embedding caches for 5x inference speedup.
                        </p>
                    </div>
                </div>

                <!-- Grand AI Challenge PS-03 -->
                <div class="award-item">
                    <div class="award-icon">ü•á</div>
                    <div class="award-content">
                        <h3>Grand AI Challenge PS-03</h3>
                        <p class="award-rank">Top 8 out of 100+ teams, Government of India</p>
                        <p class="award-description">
                            Currently competing in few-shot visual search for satellite imagery. Developed hybrid detection system combining frozen self-supervised ViT features with learnable adapters for prototype-based retrieval in multispectral satellite data.
                        </p>
                    </div>
                </div>

                <!-- CVPR 2025 Demo Track -->
                <div class="award-item">
                    <div class="award-icon">üìÑ</div>
                    <div class="award-content">
                        <h3>CVPR 2025 Demo Track</h3>
                        <p class="award-rank">Paper Accepted</p>
                        <p class="award-description">
                            Paper accepted at <strong>IEEE/CVF CVPR 2025 Demo Track</strong> as a second-year undergraduate. MSCAN: Multistage Spinal Canal Stenosis Grading Using Cross-Attention - achieving 0.971 AUROC for automated MRI-based spinal stenosis grading.
                        </p>
                    </div>
                </div>

                <!-- Smart India Hackathon 2024 -->
                <div class="award-item">
                    <div class="award-icon">ü•à</div>
                    <div class="award-content">
                        <h3>Smart India Hackathon 2024</h3>
                        <p class="award-rank">National Finalist (Top 2 out of 100+ teams)</p>
                        <p class="award-description">
                            Developed REDACT, a multimodal data privacy platform achieving 99% PII detection accuracy across text, images, and documents using BERT-based NLP with few-shot learning for domain adaptation to legal and medical contexts.
                        </p>
                    </div>
                </div>

                <!-- NeurIPS 2025 Workshop -->
                <div class="award-item">
                    <div class="award-icon">üìÑ</div>
                    <div class="award-content">
                        <h3>NeurIPS 2025 Imageomics Workshop</h3>
                        <p class="award-rank">Paper Accepted (First Author)</p>
                        <p class="award-description">
                            DentalNet: Geometric Aware Multi-View Transformer for Dental 3D Scan Analysis. Multi-modal 2D/3D fusion achieving 67% F1-score through cross-attention mechanism integrating 2D intraoral views with 3D point cloud representations.
                        </p>
                    </div>
                </div>

                <!-- ACM ICMR 2025 -->
                <div class="award-item">
                    <div class="award-icon">üìÑ</div>
                    <div class="award-content">
                        <h3>ACM ICMR 2025: MAD Workshop</h3>
                        <p class="award-rank">Paper Accepted</p>
                        <p class="award-description">
                            SocialDF: Benchmark Dataset and Detection Model for Deepfake Content. Real-world benchmark with multi-agent LLM framework outperforming SOTA lip-sync methods through fact-checking integration.
                        </p>
                    </div>
                </div>

                <!-- StarkVision Co-founder -->
                <div class="award-item">
                    <div class="award-icon">üë•</div>
                    <div class="award-content">
                        <h3>StarkVision Co-Founder</h3>
                        <p class="award-rank">Student AI/ML Research Collective, IIIT Delhi</p>
                        <p class="award-description">
                            Co-founded 20-member student research collective, leading projects accepted at CVPR 2025 (Demo Track) and ICMR 2025 with student-only authorship. Mentoring juniors in experimental design, paper writing, and navigating the publication process.
                        </p>
                    </div>
                </div>

                <!-- Academic Excellence -->
                <div class="award-item">
                    <div class="award-icon">üéì</div>
                    <div class="award-content">
                        <h3>Academic Excellence</h3>
                        <p class="award-rank">GPA: 8.76/10</p>
                        <p class="award-description">
                            Maintaining strong academic performance at IIIT Delhi while pursuing research in Computer Vision, Deep Learning, and Multi-Modal Learning. Completed coursework in Data Structures, Algorithms, Machine Learning, and Linear Algebra.
                        </p>
                    </div>
                </div>

                <!-- CBSE Board Excellence -->
                <div class="award-item">
                    <div class="award-icon">üìö</div>
                    <div class="award-content">
                        <h3>CBSE Standard 12</h3>
                        <p class="award-rank">93% in PCM+PE</p>
                        <p class="award-description">
                            Achieved 93% in CBSE Standard 12 examinations (2022-2023) with Physics, Chemistry, Mathematics, and Physical Education at JN International School, Delhi.
                        </p>
                    </div>
                </div>

            </div>
        </section>
    </main>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 Arush Gumber. Built with HTML, CSS, and JavaScript.</p>
    </footer>

    <script src="js/main.js"></script>
</body>
</html>
